#MOUNTING DRIVE

from google.colab import drive
drive.mount('/content/drive')

#IMPORTING REQUIRED LIBRARIES

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import OrderedDict
from typing import List
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from scipy import stats
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.metrics import plot_confusion_matrix
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')
%matplotlib inline

#READING THE DATASET

TRAIN_DATA_FILE = '/content/drive/MyDrive/NPCI/Project/adult.data'
TEST_DATA_FILE = '/content/drive/MyDrive/NPCI/Project/adult.test'
data_types = OrderedDict([
    ("age", "int"),
    ("workclass", "category"),
    ("fnlwgt", "int"),
    ("education", "category"),
    ("education_num", "int"),
    ("marital_status", "category"),
    ("occupation", "category"),
    ("relationship", "category"),
    ("race", "category"),
    ("sex", "category"),
    ("capital_gain", "float"),  # required because of NaN values
    ("capital_loss", "int"),
    ("hours_per_week", "int"),
    ("native_country", "category"),
    ("income_class", "category"),
])
target_column = "income_class"

def read_dataset(path):
    return pd.read_csv(
        path,
        names=data_types,
        index_col=None,
        comment='|',  # test dataset has comment in it
        skipinitialspace=True,  # Skip spaces after delimiter
        na_values={
            'capital_gain': 99999,
            'workclass': '?',
            'native_country': '?',
            'occupation': '?',
        },
        dtype=data_types,
    )

def clean_dataset(data):
    data['income_class'] = data.income_class.str.rstrip('.').astype('category')
    data = data.drop_duplicates()
    #data[target_column] = (data[target_column] == '>50K').astype(int)
    return data

def deduplicate(train_data, test_data):
    train_data['is_test'] = 0
    test_data['is_test'] = 1
    data = pd.concat([train_data, test_data])
    # For some reason concatenation converts this column to object
    data['native_country'] = data.native_country.astype('category')
    data = data.drop_duplicates()
    train_data = data[data.is_test == 0].drop('is_test', axis=1)
    test_data = data[data.is_test == 1].drop('is_test', axis=1)
    return train_data, test_data

train_data = clean_dataset(read_dataset(TRAIN_DATA_FILE))
test_data = clean_dataset(read_dataset(TEST_DATA_FILE))
train_data.head()

# DATA EXPLORATION

train_data.info()
train_data.describe().T
all_columns = list(train_data.columns)
categorical_columns = list(train_data.select_dtypes(include=['category']).columns)
numerical_columns = list(train_data.select_dtypes(include=['int64', 'float64']).columns)


# CATEGORICAL DATA

plt.figure(figsize = (15,10))
sns.countplot(train_data['workclass'])
plt.show()

#We realize that most of the people in the survey belong to the Private sector. This is a biased data as we barely have any information on the other kind of #workclasses.

train_data['workclass'].value_counts()
train_data.groupby(['workclass', 'income_class']).size()

categorical_columns = list(train_data.select_dtypes(include=['category']).columns)
print('Categorical columns:\n {}'.format(categorical_columns))

#Everyone in the survey who has worked without pay earns <=50 because... well... They aren't paid xD.Same goes for people who have never worked. Maybe their #families are filthy rich.We do see that the private sector that employes most of the people in the survey also has over 3 times the number of employees who #earn less than 50k compared to their counterparts who earn more than 50k.This may be because our data is biased.

plt.figure(figsize = (15,10))
sns.countplot(train_data[categorical_columns[1]])
plt.show()

#This is an interesting graph as most of the people in the survey have either attended HS-grad, have a Bachelor's degree or have attended some collage

train_data['education'].value_counts()
train_data.groupby(['education', 'income_class']).size()

#From this we understand that most people with lower level of education usually earn less than 50k. There are exceptions however and that may be so because of #their experiences or learning things on their own. Or just being really good at their trade.
#Only for bachelors we see the gap between people earning >50k and <=50k is fairly low. That may be so because bachelors is a degree with many trades involved #and talent and hardwork usually pays off real well.Everyone who has not studied beyond preschool earns less than 50k.On the other hand people who have #persued higher education like Masters and Doctorate are more likely to earn >50k. We need to analyze other factors to trim this down.

train_data.groupby(['education', 'workclass']).size()

#This gives us insigts on the relationship between workclass and education.
#we see that the only people who work without pay are the ones who had Assoc-acdm, are HS-Grads or those who went to some collage.We also see that no matter #the educational level, the highest number of people in each category work in the private sector.The mode of each of those columns is of the private sector as #well.

plt.figure(figsize = (15,10))
sns.countplot(train_data[categorical_columns[2]])
plt.show()

train_data['marital_status'].value_counts()

train_data.groupby(['marital_status', 'income_class']).size()

#We see that when a person is married and has a civilian spouce, they tend to have a lower difference between the two classses of income potential.The biggest #difference is among the people who are never married. Almost all of them earn less than 50k. This may be because they are relatively younger so they have #less experience or there can be a range of other factors (like education).

train_data.groupby(['marital_status', 'workclass']).size()

#We again see that in all the marital statuses, private sector is where most people work. It usually is the case with an overwhelming majority.Except for #people with a married civilian spouse where local-govt and self-employed-not-inc had 1600+ and 1000+ entries with private sectors were at 9.7k.

train_data.groupby(['marital_status', 'education']).size()

#Most people who did their masters, bachelors or went to some collage tend to have civilian spouses. Bachelors and people who went to some collage are also #amongst those who were not married.This may be because of the number of people with bachelors, hs-grads and people going to some collage are higher than most #other recordings. However, a lot of the people who did their masters did prefer civilian spouses.

plt.figure(figsize=(10,5))
sns.countplot(train_data['native_country'])
plt.show()

train_data['native_country'].value_counts()

#That is a highly biased dataset. So we can just replace all the null values with US and it will be fine.We also notice that there is no inconsistency in the #data (like US, USA, United States in one dataset) so we do not need to worry about it.

train_data.groupby(['occupation', 'education']).size()

#As we had expected, Bachelors, HS-Grads and some-collage rule this side as well. But there are some interesting things we found.In Tech SUpport, Bachelors, #Some-collage are mostly present with HS-grads coming in third followed by Assoc-voc.Bachelors, Masters and Doctorates prefer Prof-speciality fields of work. #Most masters and Doctorates work in this field. They are also the ones who usually get paid >50k so this makes a lot of sense.

train_data.groupby(['occupation', 'workclass']).size()

#Private sector is the most preferred sector except for Farming-Fishing where self-emp-not-inc are present in abundence. Since they are usually not the ones #who get paid >50k, farming is probably not a very profitable. Most of the people who work without pay also stay in this trade.

plt.figure(figsize=(15,10))
sns.countplot(train_data['race'])

#This is a white dominated dataset and we see that the ratio of race with >50k and <50k is: aie - 7.6 api - 2.7 b - 7.0 o - 9.8 w - 2.9.This concludes that #White and Asian-Pac_Islanders have a less ratio between the people earning >50k and <=50k while it is more prominent in the rest of the races, especially for #the people tagged 'Other' This may be because of education. So let's check that.

train_data.groupby(['race', 'income_class']).size()
train_data.groupby(['race', 'education']).size()

#We see that Most white people are HS-Grads and a lot of them have gone to some college. The next highs are Bachelors and masters. We see that most people #belonging to the Other category do not have many high degrees and that might explain the low income potential. We see a lot of people belonging to the Black #category are HS-Grads. Since HS-Grads have a high number of people with income potential <=50k, this may explain why the ratio is so high. For #asia-pac-islanders, a lot of people in their category have done masters (compared to other degrees it isnt that low) which may have contributed to their #higher income potential.

plt.figure(figsize=(15,10))
sns.countplot(train_data['sex'])

train_data.groupby(['sex', 'income_class']).size()

#when it comes to the ratio of Males being paid >50k and <-50k is around 2.3 but for women, the same ratio drops down to 8.1. This implies that women are #being paid less. We have to check the same for every occupation to see if women work in occupations that usually pay less. This can go both ways.

train_data.groupby(['education', 'sex']).size()

#We understand that women are a lot more prominent in the lower levels of education and then in bachelors, hsgrads and some-collage. This implies a lot of #women quit during school.

train_data.groupby(['occupation', 'sex']).size()

#Women dominate the adm-clerical, other services, priv-house-ervices. However in all the services, a majority of people get paid <=50k. We may need to check #the numeric columns and then plot a heatmap and check the corelation of all the columns with the target in order to get a better idea about the dataset.


#NUMERICAL_DATA_ANALYSIS

numerical_columns
train_data.var(axis=0)
train_data.loc[:, numerical_columns].var()
var_in_float = train_data.loc[:, numerical_columns].var()
for i in range(len(numerical_columns)):
    print('{} \t\t {}'.format(numerical_columns[i], round(float(var_in_float[i]), 3)))
#We see that fnlwgt, capital-gain and capital loss have the highest variance. This can occur either because these have a lot of information or... they have #few, very extreme values. Let's check those out.

plt.figure(figsize=(15,10))
sns.distplot(train_data['fnlwgt'])
plt.show()
plt.close()

#Do not be fooled by the tiny 0.2 steps because at the end, there's a 1e6. It means it is 1.0e+06 or 1000000 or 1 * 10^6 So that 0.2 is actually 200000. That #would explain the high variance.

plt.figure(figsize=(15,10))
sns.boxplot(train_data['fnlwgt'])
plt.show()
plt.close()

#We see that there are a large number of outliers here. Our median lies between the 0.2 * 10^6 side but a lot of other points cross our 75th percentile. We #will have to treat this column for outliers.

plt.figure(figsize=(15,10))
sns.distplot(train_data['capital_gain'])
plt.show()
plt.close()

#This graph is quite interesting. Most of our data tends towards the zero side of the graph. However, some of the data is in the 5k-20k range and there is #some data in the 100,000 range as well! Now that outlier right there would throw off our variance by a lot. We need to deal with those outliers eventually or #when we try to make models later, we will not be able to make a good prediction.
plt.figure(figsize=(15,10))
sns.boxplot(train_data['capital_gain'])
plt.show()
plt.close()

#That just looks like a lot of outliers as almost all of our data was centered towards 0 impling very few people got a capital gain. Without much capital #gain, it is difficult to break the <=50k barrier. That would help explain why so many people in the survey had a income potential of <=50k.
plt.figure(figsize=(15,10))
sns.distplot(train_data['capital_loss'])
plt.show()
plt.close()

#We again see the data is centered towards 0 with some outliers near 2000. We will have to clean or scale this data.
plt.figure(figsize=(15,10))
sns.boxplot(train_data['capital_loss'])
plt.show()
plt.close()

#Again, there are a large amount of people with no capital loss. We also saw a large amount of people do not have any capital gain either. So maybe people in #our sample do not invest or have passive income or take risks and so on. This is kind of sad to see. But at least there were not large losses. The highest #loss we see is somewhere in the range of 5000.
plt.figure(figsize=(15,10))
sns.distplot(train_data['education_num'])
plt.show()
plt.close()

plt.figure(figsize=(15,10))
sns.boxplot(train_data['education_num'])
plt.show()
plt.close()

#We see that most of the people fall within the 9-12 range with data skewed towards the left. Which is the HS-grad part of the graph. And few people are well #below our education number threshold at 4 to 1.
plt.figure(figsize=(15,10))
sns.distplot(train_data['hours_per_week'])
plt.show()
plt.close()

#We see that a lot of people work around 40 hours per week. We see there are some people who work towards the 0 side of the graph. They may be people who work #without pay and those who do not get paid at all. We will check for those as well.
plt.figure(figsize=(15,10))
sns.boxplot(train_data['hours_per_week'])
plt.show()
plt.close()

#We see a lot of people work 40 hour weeks but that ranges from 30-50. However a lot of people people work a lot longer and less than that. Some even work 100 #hour weeks! They are either very passionate, or are having a very bad time.
plt.figure(figsize=(15,10))
sns.distplot(train_data['age'])
plt.show()
plt.close()

#We see the Age is right skewed as more people at an younger age work in this survey.
plt.figure(figsize=(15,10))
sns.boxplot(train_data['age'])
plt.show()
plt.close()

#We see that most people who work are within the age group of 17 to a little less than 80. 80 is... well hats off to them and to those who work well beyond #that up to their early 90s. It is facinating to see people work till that age. They must be very passionate about what they do. Or there may be something #sadder at play.
#Correlation between the numeric columns.
train_data.corr()



#PRE-PROCESSING

# Dealing with nulls
train_data.isnull().sum()
train_data['occupation'].fillna(method='ffill', inplace=True)
null_columns = train_data.columns[train_data.isnull().any()]
train_data[null_columns].isnull().sum()
for i in list(null_columns):
    train_data[i].fillna(train_data[i].mode().values[0],inplace=True)
test_data['occupation'].fillna(method='ffill', inplace=True)
null_columns1 = test_data.columns[test_data.isnull().any()]
test_data[null_columns1].isnull().sum()
for i in list(null_columns1):
    test_data[i].fillna(test_data[i].mode().values[0],inplace=True)
train_data.isnull().sum()


# Label Encoding
encoded_train_data = train_data
encoded_test_data = test_data
def label_encoding(categorical_columns: List[str], encoded_data: pd.DataFrame) -> None:
    for column in categorical_columns:
        lb_encoding = LabelEncoder()
        encoded_data[column] = lb_encoding.fit_transform(encoded_data[column])
    return None
label_encoding(categorical_columns, encoded_train_data)
label_encoding(categorical_columns, encoded_test_data)


#Scaling Data
COLUMN_NAME = list(train_data.columns)

# Data Scaling for train data
scaler = MinMaxScaler()
minmax_df = scaler.fit_transform(encoded_train_data)
scaled_encoded_adult_data = pd.DataFrame(minmax_df, columns= COLUMN_NAME)
scaled_encoded_adult_data.sample(10)
scaled_encoded_adult_data.isnull().sum()

# Data Scaling for test data
scaler = MinMaxScaler()
minmax_df = scaler.fit_transform(encoded_test_data)
scaled_encoded_test_data = pd.DataFrame(minmax_df, columns= COLUMN_NAME)
scaled_encoded_test_data.sample(10)
scaled_encoded_test_data.isnull().sum()
scaled_encoded_adult_data.describe().T
scaled_encoded_test_data.describe().T

# Outlier Detection
for i in range(len(numerical_columns)):
    plt.figure(figsize=(15,10))
    sns.boxplot(scaled_encoded_adult_data[numerical_columns[i]])
plt.show()
plt.close()
#As we can see in the graphs above, Scaling does nothing to the distribution and does not deal with the outliers either. We have to take care of the outliers.
#If the columns are continuous, we replace the outliers with the value of the medians and if they are categorical, we replace the outliers with the mode. We #have already established the numeric and categorical columns. So, it will be easier for us to deal with them now.

# This takes a column of the dataframe (a series), 
# checks for the percentile we want to check it for and then calculates and the upper and lower bounds
def outlier_detector(datacolumn):
    sorted(datacolumn)
    Q1,Q3 = np.percentile(datacolumn,[25,75])
    IQR = Q3 - Q1
    lower_bound = Q1-(1.5*IQR)
    upper_bound = Q3+(1.5*IQR)
    return lower_bound,upper_bound
lowerbound, upperbound = outlier_detector(scaled_encoded_adult_data['age'])
lowerbound, upperbound
scaled_encoded_adult_data[(scaled_encoded_adult_data.age < lowerbound) | (scaled_encoded_adult_data.age > upperbound)]
#Looping the outlier_detector through all numerical columns and then replacing them with the median.
#We should not consider the sparse columns so we will remove those from our outlier treatment columns
new_columns = numerical_columns.copy()
#Sparse column, must not be treated
new_columns.remove('capital_gain')
new_columns.remove('capital_loss')
new_columns
# FOR TRAIN DATA
treated_scaled_encoded_adult_data = scaled_encoded_adult_data.copy()
for i in new_columns:
    lowerbound, upperbound = outlier_detector(treated_scaled_encoded_adult_data[i])
    median = treated_scaled_encoded_adult_data[i].median()
    lst = (list((treated_scaled_encoded_adult_data[(treated_scaled_encoded_adult_data[i] < lowerbound) | 
                                                       (treated_scaled_encoded_adult_data[i] > upperbound)][i])))
    
    treated_scaled_encoded_adult_data[i] = treated_scaled_encoded_adult_data[i].replace(
        to_replace = lst, value = median)
    print('{}: number of outliers: {}'.format(i,treated_scaled_encoded_adult_data[
        (treated_scaled_encoded_adult_data[i] < lowerbound) |
        (treated_scaled_encoded_adult_data[i] > upperbound)][i]))
# FOR TEST DATA
treated_scaled_encoded_test_data = scaled_encoded_test_data.copy()
for i in new_columns:
    lowerbound, upperbound = outlier_detector(treated_scaled_encoded_test_data[i])
    median = treated_scaled_encoded_test_data[i].median()
    lst = (list((treated_scaled_encoded_test_data[(treated_scaled_encoded_test_data[i] < lowerbound) | 
                                                       (treated_scaled_encoded_test_data[i] > upperbound)][i])))
    
    treated_scaled_encoded_test_data[i] = treated_scaled_encoded_test_data[i].replace(
        to_replace = lst, value = median)
    print('{}: number of outliers: {}'.format(i,treated_scaled_encoded_test_data[
        (treated_scaled_encoded_test_data[i] < lowerbound) |
        (treated_scaled_encoded_test_data[i] > upperbound)][i]))

fig,ax=plt.subplots(figsize=(20,15))
ax=sns.heatmap(treated_scaled_encoded_adult_data.corr(),annot=True)

# TRAIN-TEST SPLIT VALIDATION
FEATURES = list(treated_scaled_encoded_adult_data.columns)[:-1]
TARGET = "income_class"
x_train, y_train, x_test, y_test = treated_scaled_encoded_adult_data[FEATURES], treated_scaled_encoded_adult_data[TARGET], treated_scaled_encoded_test_data[FEATURES], treated_scaled_encoded_test_data[TARGET]

# LOGISTIC REGRESSION
logistic_regressor = LogisticRegression()
logistic_regressor.fit(x_train, y_train)
logistic_train_score = logistic_regressor.score(x_train, y_train)
logistic_test_score = logistic_regressor.score(x_test, y_test)
logistic_prediction = logistic_regressor.predict(x_test)
print(f"Train Score: {logistic_train_score}\nTest Score: {logistic_test_score}")
logistic_mse = mean_squared_error(y_test, logistic_prediction)
logistic_rmse = np.sqrt(logistic_mse)
print(logistic_mse, logistic_rmse)

#KNN CLASSIFIER

error_rate = []
k_values = list(filter(lambda x: x%2==1, range(0,50)))
best_k = 0
for i in k_values:
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(x_train,y_train)
    pred_i = knn.predict(x_test)
    error_rate.append(np.mean(pred_i != y_test))
print(error_rate.index(np.min(error_rate)))
plt.figure(figsize=(10,10))
plt.plot(k_values,error_rate,color='blue', linestyle='dashed', marker='o',
         markerfacecolor='red', markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')
plt.show()
plt.close()
knn_classifier = KNeighborsClassifier(n_neighbors=43)
knn_classifier.fit(x_train, y_train)
knn_train_score = knn_classifier.score(x_train, y_train)
knn_test_score = knn_classifier.score(x_test, y_test)
print('Train score: {}\nTest score: {}'.format(knn_train_score, knn_test_score))
knn_prediction = knn_classifier.predict(x_test)
knn_classifier_mse = mean_squared_error(y_test, knn_prediction)
knn_classifier_rmse = np.sqrt(knn_classifier_mse)
print('MSE: {}\nRMSE: {}'.format(knn_classifier_mse, knn_classifier_rmse))


# MODEL EVALUATION
modlist = [('LogisticRegression', logistic_regressor), ('KNN Classifier', knn_classifier), ('Decision Tree Classifier', dtree_classifier), 
           ('Ada-Boost Classifier', adaboost_classifier), ('RandomForest Classifier', random_forest_classifier)] 

models = [j for j in modlist]
print()
print('========================== Model Evaluation Results ========================' "\n")  

for i, v in models:
    scores = cross_val_score(v, x_train, y_train, cv=10)
    accuracy = metrics.accuracy_score(y_train, v.predict(x_train))
    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(x_train))
    classification = metrics.classification_report(y_train, v.predict(x_train))
    print('===== {} ====='.format(i))
    print()
    print ("Cross Validation Mean Score: ", '{}%'.format(np.round(scores.mean(), 3) * 100))  
    print() 
    print ("Model Accuracy: ", '{}%'.format(np.round(accuracy, 3) * 100)) 
    print()
    print("Confusion Matrix:" "\n", confusion_matrix)
    print()
    print("Classification Report:" "\n", classification) 
    print()

#Support Vector Machine
svc = SVC(kernel='rbf')
svc.fit(x_train, y_train)

svc_train_score = svc.score(x_train, y_train)
svc_test_score = svc.score(x_test, y_test)
print('Train score: {}\nTest score: {}'.format(svc_train_score, svc_test_score))

svc_prediction = svc.predict(x_test)
svc_mse = mean_squared_error(y_test, svc_prediction)
svc_rmse = np.sqrt(svc_mse)
print('MSE: {}\nRMSE: {}'.format(svc_mse, svc_rmse))
#Plot between confusion matrix vs Actuals vs Predicted
conf_matrix = confusion_matrix(y_true=y_test, y_pred=svc_prediction)
fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
plt.close()
#Printing precision_score, recall_score, accuracy_score and f1_score
print('Precision: %.3f' % precision_score(y_test, svc_prediction))
print('Recall: %.3f' % recall_score(y_test, svc_prediction))
print('Accuracy: %.3f' % accuracy_score(y_test, svc_prediction))
print('F1 Score: %.3f' % f1_score(y_test, svc_prediction))
    
#DECISION TREE
dtree_classifier = DecisionTreeClassifier(min_impurity_decrease = 0.05)
dtree_classifier.fit(x_train, y_train)
dtree_train_score = dtree_classifier.score(x_train, y_train)
dtree_test_score = dtree_classifier.score(x_test, y_test)
print('Train score: {}\nTest score: {}'.format(dtree_train_score, dtree_test_score))
dtree_prediction = dtree_classifier.predict(x_test)
dtree_mse = mean_squared_error(y_test, svc_prediction)
dtree_rmse = np.sqrt(dtree_mse)
print('MSE: {}\nRMSE: {}'.format(dtree_mse, dtree_rmse))

#ADA - BOOST CLASSIFIER
adaboost_classifier = AdaBoostClassifier(n_estimators=3)
adaboost_classifier.fit(x_train,y_train)
adaboost_train_score = adaboost_classifier.score(x_train,y_train)
adaboost_test_score = adaboost_classifier.score(x_test,y_test)
print('Train score: {}\nTest score: {}'.format(adaboost_train_score, adaboost_test_score))
adaboost_prediction = adaboost_classifier.predict(x_test)
adaboost_mse = mean_squared_error(y_test, adaboost_prediction)
adaboost_rmse = np.sqrt(adaboost_mse)
print('MSE: {}\nRMSE: {}'.format(adaboost_mse, adaboost_rmse))


#RANDOM FOREST
random_forest_classifier = RandomForestClassifier(n_estimators=40, min_samples_split=15, min_impurity_decrease=0.05)
random_forest_classifier.fit(x_train, y_train)
random_forest_train_score = random_forest_classifier.score(x_train,y_train)
random_forest_test_score = random_forest_classifier.score(x_test,y_test)
print('Train score: {}\nTest score: {}'.format(random_forest_train_score, random_forest_test_score))
random_forest_prediction = random_forest_classifier.predict(x_test)
random_forest_mse = mean_squared_error(y_test, random_forest_prediction)
random_forest_rmse = np.sqrt(random_forest_mse)
print('MSE: {}\nRMSE: {}'.format(random_forest_mse, random_forest_rmse))
